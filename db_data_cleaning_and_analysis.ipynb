{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory data analysis - data cleaning and transformation\n",
    "- Data cleaning is performed to convert columns to the correct format, handle nulls, and deal with missing values and outliers in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports and data loading\n",
    "- Required modules are imported along with required classes defined in other files\n",
    "- Data is loaded from .csv file into a pd dataframe \n",
    "- An instance of the DataTransform class is initialised for data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "import seaborn as sns\n",
    "from datetime import datetime \n",
    "from db_datatransform import DataTransform\n",
    "from db_info import DataFrameInfo\n",
    "from db_info import read_csv\n",
    "from db_clean_data import Plotter\n",
    "from db_clean_data import DataFrameTransform\n",
    "from db_datatransform import DataTransform\n",
    "from db_info import DataFrameInfo\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'loan_payments.csv'\n",
    "loan_payments_df = read_csv(filename)  # calls the read_csv funciton to load data \n",
    "loan_payments_df = loan_payments_df.drop(columns=loan_payments_df.columns[0], axis=1) # remove additional index column\n",
    "column_names = loan_payments_df.columns.tolist() # creates a list of the column headings as strings \n",
    "data_transform_instance = DataTransform(loan_payments_df) # creates an instance of the DataTransform class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Converting columns to the correct format\n",
    "- Columns identified as being the wrong data type are transformed using methods created in the DataTransform class\\\n",
    "- Columns are listed and then converted to datetime, float, string or categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_convert_to_datetime = ['issue_date', \n",
    "                                 'earliest_credit_line', \n",
    "                                 'last_payment_date',\n",
    "                                 'next_payment_date', \n",
    "                                 'last_credit_pull_date'] # list of strings specifying columns to be converted\n",
    "col_to_convert_to_float = ['term','employment_length'] # list of strings of column names\n",
    "col_to_convert_to_str = ['grade', 'sub_grade'] # list of strings of column names\n",
    "col_to_convert_to_categorical = ['home_ownership',\n",
    "                                    'verification_status', \n",
    "                                    'loan_status', \n",
    "                                    'payment_plan', \n",
    "                                    'purpose', \n",
    "                                    'application_type']  # list of strings of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(col_to_convert_to_datetime)): # loops over list of column names\n",
    "       datetime_format = '%b-%Y'\n",
    "       data_transform_instance.obj_to_datetime(col_to_convert_to_datetime[i],datetime_format) # calls the obj_to_datetime method to convert data to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(col_to_convert_to_float)): # loops over list of column names\n",
    "       data_transform_instance.obj_to_int(col_to_convert_to_float[i]) # calls the obj_to_int method to convert data to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(col_to_convert_to_str)): # loops over list of column names\n",
    "       data_transform_instance.obj_to_str(col_to_convert_to_str[i]) # calls the obj_to_string method to convert data to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(col_to_convert_to_categorical)): #loops over list of column names\n",
    "       data_transform_instance.obj_to_cat(col_to_convert_to_categorical[i]) # calls the obj_to_ method to convert data to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Handling Nulls\n",
    "- Null values are identified using methods from the DataFrameInfo class\n",
    "- Null values are handled either by dropping the entire column, imputing the data, or dropping null values depending on the column type and percentage of null values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Identifying null values \n",
    "- Null values are identified using the null_percentage method of the DataFrameInfo class, columns with null values are appended to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_info_instance = DataFrameInfo(loan_payments_df) # initialises an instnce of the class to obtain information on the dataframe\n",
    "null_columns = [] # initialise list of null columns\n",
    "for i in range (0, len(column_names)):\n",
    "    null_pc = nulls_info_instance.null_percentage(column_names[i])\n",
    "    if null_pc > 0.0:\n",
    "        null_columns.append(column_names[i]) # append to list of columns if there are any null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(column_names)):\n",
    "    null_pc = nulls_info_instance.null_percentage(column_names[i])\n",
    "    print(column_names[i], null_pc)\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Handling null values\n",
    "- Columns with a high percentage of null values (>50%) are dropped\n",
    "- Columns with a small amount (1<%<49) of null values will be handled by imputing values, as dropping these rows could cause information loss\n",
    "- Columns with a very small amount (<1%) of null values will have rows containing null values dropped\n",
    "\n",
    "- Columns and rows containing null values are dropped using the drop_column and drop_null_rows methods of the DataFrameTransform class\n",
    "- Descriptive stastics are calculated for columns that will be imputed to determine if missing values are imputed by the mean, mode or median value\n",
    "- Values are imputed using methods from the DataFrameTransform class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['mths_since_last_delinq', \n",
    "                      'mths_since_last_record', \n",
    "                      'next_payment_date', \n",
    "                      'mths_since_last_major_derog'] # list of strings of columns with > 50% null values\n",
    "columns_to_impute = ['funded_amount','term','int_rate','employment_length'] # list of strings of columns with a small amount of null values \n",
    "columns_to_drop_null_value_rows = ['last_payment_date', \n",
    "                                      'last_credit_pull_date', \n",
    "                                      'collections_12_mths_ex_med'] # list of strings of columns with < 1% null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_payments_df_copy = loan_payments_df.copy() #create copy of df before removing any values for data preservation\n",
    "remove_null_instance = DataFrameTransform(loan_payments_df_copy) # initialises an instance of the DataFrameTransform class for dealing with null values\n",
    "df_info_instance = DataFrameInfo(loan_payments_df_copy) # initialises an instnce of the class to get info on the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_drop)):\n",
    "      loan_payments_df_copy = remove_null_instance.drop_column(columns_to_drop[i]) # drops columns with > 50 % null values\n",
    "for i in range(0, len(columns_to_drop_null_value_rows)):\n",
    "      loan_payments_df_copy = remove_null_instance.drop_null_rows(columns_to_drop_null_value_rows[i]) # drops rows with null values in specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "      mean = df_info_instance.get_mean(columns_to_impute[i])\n",
    "      print('MEAN', columns_to_impute[i], mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "      stdv = df_info_instance.get_stdev(columns_to_impute[i])\n",
    "      print('STDEV', columns_to_impute[i], stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "       mode = df_info_instance.get_mode(columns_to_impute[i])\n",
    "       print('MODE', columns_to_impute[i], mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "       median = df_info_instance.get_median(columns_to_impute[i])\n",
    "       print('MEDIAN', columns_to_impute[i], median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "       ranges = df_info_instance.get_range(columns_to_impute[i])\n",
    "       print('RANGE',columns_to_impute[i], ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(columns_to_impute)):\n",
    "       df_info_instance.get_normal_dist(columns_to_impute[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_payments_df_copy = remove_null_instance.impute_na_with_mode('term') # impute null values with mode, as this is categorical data\n",
    "loan_payments_df_copy = remove_null_instance.impute_na_with_median('employment_length') # impute null value with median, to keep all values as whole numbers \n",
    "loan_payments_df_copy = remove_null_instance.impute_na_with_mean('funded_amount') # impute null values with mean as data is continuous with a normal distribution \n",
    "loan_payments_df_copy = remove_null_instance.impute_na_with_mean('int_rate') # impute null values with mean as data is continuous with a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Checking null values again\n",
    "- Null values are checked again after the identified nulls have been dropped or imputed to ensure no null values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_copy = loan_payments_df_copy.columns.tolist() # creates a list of the remaining column headings as strings \n",
    "null_columns_copy = []\n",
    "for i in range (0, len(column_names_copy)): # to check that the correct columns and rows have been dropped and view null percentages to confirm \n",
    "    null_pc = df_info_instance.null_percentage(column_names_copy[i])\n",
    "    print(column_names_copy[i], null_pc)\n",
    "    if null_pc > 0.0:\n",
    "      null_columns_copy.append(column_names_copy[i]) # append columns with null values to list \n",
    "print(null_columns_copy) # check print to ensure correct columns and rows have been dropped "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Identifying skew\n",
    "- Skewed columns are identified through data visualisation using methods from the Plotter class\n",
    "- The skew of each column is also assigned a numerical value calculated using statistical methods\n",
    "- Columns with a numeric skew value <-2 or >2 are defined as skewed columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Data visualisation\n",
    "- Data is visualised for each column using historgrams and KDE plots generated from the Plotter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_instance = Plotter(loan_payments_df_copy) # initialise an instance of the plotter class for data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # visualise data to observe skew\n",
    "for i in range(0, len(column_names_copy)):\n",
    "      plotter_instance.plot_hist(column_names_copy[i])\n",
    "\n",
    "#for i in range(0, len(column_names_copy)):\n",
    " #     plotter_instance.plot_KDE(column_names_copy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df_skew = loan_payments_df_copy.skew(axis=0,numeric_only = True) # obtain the skew of each numeric column in the dataframe\n",
    "print(loan_df_skew)\n",
    "check_skewed_columns = loan_df_skew.index\n",
    "skewed_columns = []\n",
    "for i in range(0, len(loan_df_skew)): \n",
    "      if loan_df_skew.iloc[i] > 2 or loan_df_skew.iloc[i] < -2: # append columns with a skew < -2 or > 2 to the list\n",
    "         skewed_columns.append(check_skewed_columns[i])\n",
    "print(skewed_columns) # show skewed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Skewed columns to ignore\n",
    "- Skewed columns that are not appropriate candidates for transformation are ignored and removed from skewed_columns\n",
    "- Skewed columns with a majority of 0 values are ignored\n",
    "- Skewed columns containing categroical data or ID data are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_columns_to_ignore = ['id','member_id','delinq_2yrs','inq_last_6mths','collections_12_mths_ex_med'] # skewed columns that do not need to be transformed\n",
    "zero_maj_skewed_columns_to_ignore = ['out_prncp','out_prncp_inv','total_rec_late_fee','collection_recovery_fee'] # list of columns containing a majority of 0 values\n",
    "for i in range(0, len(skewed_columns_to_ignore)):\n",
    "      skewed_columns.remove(skewed_columns_to_ignore[i]) # removes columns that represent IDs/categorical data from list of skewed columns\n",
    "for i in range(0, len(zero_maj_skewed_columns_to_ignore)):\n",
    "      skewed_columns.remove(zero_maj_skewed_columns_to_ignore[i]) # removes columns that contain a majority of 0 values, meaning transformations are not appropriate\n",
    "print(skewed_columns) # check to ensure correct cols are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 Skew transformations \n",
    "- Skewed columns are identified, but no skew transformations are performed to enable querying and analysis of the data in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Identifying and handling outliers\n",
    "- Outliers are identified using data visualisation methods from the Plotter class \n",
    "- Outliers are handled using methods from the DataFrameTransform class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Data visualisation\n",
    "- Data is visualised for each column using historgrams and KDE plots generated from the Plotter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_payments_df_transformed = loan_payments_df_copy.copy() # create copy of transformed data with appropriate naming\n",
    "transform_instance = DataFrameTransform(loan_payments_df_transformed) # initialise an instance of the class with the transformed dataframe\n",
    "transformed_plotter_instance = Plotter(loan_payments_df_transformed) # initialise an instance of the plotter class for data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # visualise data to identify outliers \n",
    "for i in range(0, len(column_names_copy)):\n",
    "      transformed_plotter_instance.plot_hist(column_names_copy[i])\n",
    "\n",
    "#for i in range(0, len(column_names_copy)):\n",
    " #     transformed_plotter_instance.plot_KDE(column_names_copy[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Handling outliers\n",
    "- Several outliers that were far higher than the normal distribution of data were identified, these were removed using the remove_top_val method of the DataFrameTransform class\n",
    "- Negative outliers were identified in columns where context specific knowledge indicated that negative values were not logical, these were removed using the remove_negatives method of the DataFrameTransform class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers observed in visualisation of data \n",
    "columns_with_max_outliers = ['total_rec_late_fee','open_accounts','total_accounts','collection_recovery_fee'] # list of strings of column names for columns with high values to remove\n",
    "for i in range(0, len(columns_with_max_outliers)):\n",
    "      loan_payments_df_transformed = transform_instance.remove_top_val(columns_with_max_outliers[i]) # remove max values\n",
    "# additional to remove highest val again\n",
    "loan_payments_df_transformed = transform_instance.remove_top_val('collection_recovery_fee') \n",
    "loan_payments_df_transformed = transform_instance.remove_top_val('total_rec_late_fee') \n",
    "\n",
    "columns_with_negatives = ['recoveries','last_payment_amount'] # list of strings of column names for columns with -ve values to remove\n",
    "for i in range(0, len(columns_with_negatives)):\n",
    "      loan_payments_df_transformed = transform_instance.remove_negatives(columns_with_negatives[i]) # remove negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Correlated columns\n",
    "- Overly correlated columns are identified with a correlation heatmap but no correlated columns are dropped in order to enable querying and analysis of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_plotter_instance.plot_corr_matrix() # visualise correlated columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Saving the cleaned data\n",
    "- Data cleaning has been completed and the cleaned data is saved to a pickle file for data preservation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_payments_df_transformed.to_pickle('cleaned_data.pickle') # saves data in pickle format to preserve data types/data transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data analysis and visualisation\n",
    "- Further analysis is performed on the data to gain deeper insights now the data has been transformed\n",
    "- Data is loaded to a dataframe from the saved pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_payments_df = pd.read_pickle('cleaned_data.pickle') # load in cleaned and transformed data from pickle file\n",
    "cleaned_data_plotter_instance = Plotter(loan_payments_df)   # initialise an instance of the plotter class with cleaned data\n",
    "column_names = loan_payments_df.columns.tolist() # create list of column names for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Summarise what % of loans are recovered against investor funding and total amount funded\n",
    "- Recovered loans are defined as those where the outstanding principal is 0 \n",
    "- Percentage is calculated as a percentage of total loans issued\n",
    "- EDA revealed a 1:1 correlation between out_prncp and out_prncp_inv, percentage recovered is therefore the same for both measures\n",
    "- Results are visualised as a bar plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise currently what percentage of the loans are recovered against the investor funding and the total amount funded\n",
    "out_prncp_zeros = (loan_payments_df.out_prncp == 0.00).sum()  \n",
    "loans_recov_against_total_funding = (out_prncp_zeros/(len(loan_payments_df)))*100\n",
    "print(f\"Percentage of the loans recovered against the investor funding and the total amount funded = {loans_recov_against_total_funding.round(2)} %\")\n",
    "loans_recov_against_inv_funding = loans_recov_against_total_funding # out_prncp_inv is same % as columns have 1:1 correlation\n",
    "funding = ['total_funding','investor_funding']\n",
    "recovery_pc = [loans_recov_against_total_funding, loans_recov_against_inv_funding]\n",
    "funding_df = pd.DataFrame({'Funding': funding, 'Recovery_percentage': recovery_pc}) # load data into df to enable plotting\n",
    "fig1 = plt.figure(1)\n",
    "plt.bar(funding_df['Funding'], funding_df['Recovery_percentage'], width=0.8) # plot bar chart of % recovery\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Visualise what % of the total amount would be recovered up to 6 months in the future\n",
    "- The remaining balance of the loans is calculcated monthly up to 6 months in the future\n",
    "- The monthly installment is subtracted from the remaining balance to calculcate the remaining balance for each month\n",
    "- The remaining balance is summed for each month to calculate the percentage recovery\n",
    "- This projection is visualised with a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise what percentage of the total amount would be recovered up to 6 months' in the future.\n",
    "loan_payments_recovery_projection_df = loan_payments_df.copy()\n",
    "loan_payments_recovery_projection_df['remaining_balance'] = loan_payments_recovery_projection_df['loan_amount'] -  loan_payments_recovery_projection_df['total_payment'] # calculate remaining balance of each loan\n",
    "loan_payments_recovery_projection_df['month1'] = loan_payments_recovery_projection_df['remaining_balance'] - loan_payments_recovery_projection_df['instalment'] # minus monthly payment to get remaining balance for that month\n",
    "loan_payments_recovery_projection_df['month2'] = loan_payments_recovery_projection_df['remaining_balance'] - (loan_payments_recovery_projection_df['instalment']*2) \n",
    "loan_payments_recovery_projection_df['month3'] = loan_payments_recovery_projection_df['remaining_balance'] - (loan_payments_recovery_projection_df['instalment']*3)\n",
    "loan_payments_recovery_projection_df['month4'] = loan_payments_recovery_projection_df['remaining_balance'] - (loan_payments_recovery_projection_df['instalment']*4)\n",
    "loan_payments_recovery_projection_df['month5'] = loan_payments_recovery_projection_df['remaining_balance'] - (loan_payments_recovery_projection_df['instalment']*5)\n",
    "loan_payments_recovery_projection_df['month6'] = loan_payments_recovery_projection_df['remaining_balance'] - (loan_payments_recovery_projection_df['instalment']*6)\n",
    "\n",
    "month1_pc = (((loan_payments_recovery_projection_df.month1 <= 0.00).sum())/(len(loan_payments_df)))*100 # calculate percentage of loans recovered after each month\n",
    "month2_pc = (((loan_payments_recovery_projection_df.month2 <= 0.00).sum())/(len(loan_payments_df)))*100\n",
    "month3_pc = (((loan_payments_recovery_projection_df.month3 <= 0.00).sum())/(len(loan_payments_df)))*100\n",
    "month4_pc = (((loan_payments_recovery_projection_df.month4 <= 0.00).sum())/(len(loan_payments_df)))*100\n",
    "month5_pc = (((loan_payments_recovery_projection_df.month5 <= 0.00).sum())/(len(loan_payments_df)))*100\n",
    "month6_pc = (((loan_payments_recovery_projection_df.month6 <= 0.00).sum())/(len(loan_payments_df)))*100\n",
    "\n",
    "month_no = [1,2,3,4,5,6]\n",
    "loans_recovered_pc = [month1_pc, month2_pc, month3_pc, month4_pc, month5_pc, month6_pc]\n",
    "recovery_df = pd.DataFrame({'Month': month_no,'Recovery_percentage': loans_recovered_pc}) # create df to plot data \n",
    "fig2 = plt.figure(2)\n",
    "sns.scatterplot(data=recovery_df, x='Month', y='Recovery_percentage') # scatter plot of data to visualise projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Calculate the percentage of charged off loans historically \n",
    "- Charged off loans represent a loss to the company\n",
    "- The percentage of loans marked as charged off is calculated using the loan_status categorisation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of charged off loans historically \n",
    "charged_off_loans = (loan_payments_df.loan_status == 'Charged Off').sum()  \n",
    "charged_off_loans_pc = (charged_off_loans/(len(loan_payments_df)))*100\n",
    "print(f\"Percentage of charged off loans historically = {charged_off_loans_pc.round(2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Calculate the total amount paid towards these loans before being charged off\n",
    "- Charged off loans are ifentified and the amount paid towards the loans is calculated\n",
    "- The amount paid is summed and divided by the sum of the total loan amounts to obtain a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the total amount that was paid towards these loans before being charged off.\n",
    "charged_off_loans_df = loan_payments_df.loc[loan_payments_df['loan_status']=='Charged Off']\n",
    "total_loan_amount = charged_off_loans_df['loan_amount'].sum()\n",
    "total_amount_paid = charged_off_loans_df['total_payment'].sum()\n",
    "total_amount_paid_pc = (total_amount_paid/total_loan_amount)*100\n",
    "print(f\"total amount that was paid towards these loans before being charged off = £{total_amount_paid.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Calulcate the loss in revenue generated if these loans finished their term\n",
    "- The time between the loan issue date and last payment date is calculated and converted to months \n",
    "- The loan payment term remaining is calculcated by subtracting the monthly payments paid so far from the term of the loan\n",
    "- The amount remaining to be paid for the loans is calculated from the remaining months on the loan term multiplied by the monthly payment\n",
    "- This gives the total potential revenue lost from loans that have been charged off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss in revenue these loans would have generated for the company if they had finished their term. \n",
    "time_passed = ((charged_off_loans_df['last_payment_date'] - charged_off_loans_df['issue_date'])) # calculate how much time has passed of the loan term\n",
    "time_passed_days = time_passed.dt.days # convert to days \n",
    "charged_off_loans_df_calc = charged_off_loans_df.copy()\n",
    "charged_off_loans_df_calc['time_passed_months'] = (time_passed_days/30.5).round() # convert to int value and divide by avg month length to get no of months\n",
    "charged_off_loans_df_calc['time_remaining'] = charged_off_loans_df_calc['term'] - charged_off_loans_df_calc['time_passed_months'] # calculate number of months left of the term\n",
    "charged_off_loans_df_calc['lost_revenue'] = charged_off_loans_df_calc['time_remaining']*charged_off_loans_df_calc['instalment'] # amount that would be paid over the remaining term\n",
    "total_revenue_loss = charged_off_loans_df_calc['lost_revenue'].sum()\n",
    "print(f\"total loss in revenue these loans would have generated for the company  = £{total_revenue_loss.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Calculate the % of users behind with loan payments\n",
    "- Users behind with loan payments are categorised as Late (16-30 days) or Late (31-120 days)\n",
    "- Users with loans in these categories are summed \n",
    "- This value is divided by the total number of loans to obtain a percentage value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentage of users behind with loan payments \n",
    "late_loans_1 = (loan_payments_df.loan_status == 'Late (16-30 days)').sum()   # count no of loans marked as late\n",
    "late_loans_2 = (loan_payments_df.loan_status == 'Late (31-120 days)').sum()   # count no of loans marked as late\n",
    "late_loans_pc = ((late_loans_1 + late_loans_2)/(len(loan_payments_df)))*100 # calculate total % of late loans \n",
    "print(f\"total percentage of users behind with loan payments  = {late_loans_pc.round(2)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Calculate the loss to the company if loan status of these users was changed to charged off \n",
    "- The reminaing amount owed is summed for users who are behind with loans to calcualte the potential loss in revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how much loss the company would incur their status was changed to Charged Off\n",
    "late_loans_df = loan_payments_df.apply(lambda row: row[loan_payments_df['loan_status'].isin(['Late (16-30 days)','Late (31-120 days)'])]) # filter df to obtain only rows with late status \n",
    "loss_incurred = late_loans_df['out_prncp'].sum() # sum the outstanding amount for each late loan to calculate loss \n",
    "print(f\"total loss the company would incur if their status was changed to Charged Off  = £{loss_incurred.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Calculated the projected loss if these customers were to finish their full loan term\n",
    "- The time between the loan issue date and last payment date is calculated and converted to months \n",
    "- The loan payment term remaining is calculcated by subtracting the monthly payments paid so far from the term of the loan\n",
    "- The remaining amount that would be paid towards the loans is calculated from the remaining months on the loan term multiplied by the monthly payment\n",
    "- The projected loss is calculated as the outstanding amount on the loans after the full payment term is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the projected loss of these loans if the customer were to finish the full loans term?\n",
    "time_passed_lateloans = ((late_loans_df['last_payment_date'] - late_loans_df['issue_date'])) # calculate how much time has passed of the loan term\n",
    "time_passed_days_lateloans = time_passed_lateloans.dt.days # convert to days \n",
    "late_loans_df['time_passed_months'] = (time_passed_days_lateloans/30.5).round() # convert to int value and divide by avg month length to get no of months\n",
    "late_loans_df['time_remaining'] = late_loans_df['term'] - late_loans_df['time_passed_months'] # calculate number of months left of the term\n",
    "late_loans_df['outstanding_payments'] = late_loans_df['time_remaining']*late_loans_df['instalment'] # amount that would be paid over the remaining term\n",
    "projected_loss = late_loans_df['outstanding_payments'].sum() \n",
    "print(f\"total projected loss of these loans if the customers were to finish the full loans term  = £{projected_loss.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 If customers late on payments converted to Charged Off, what percentage of total expected revenue do these customers and the customers who have already defaulted on their loan represent?\n",
    "- A subset of data is created including all users who are late on payments and those who have had their loans charged off\n",
    "- Monthly revenue from this subset of users is summed and divided by total monthly revenue to calculcate the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If customers late on payments converted to Charged Off, what percentage of total expected revenue do these customers and the customers who have already defaulted on their loan represent?\n",
    "lost_revenue_df = loan_payments_df.apply(lambda row: row[loan_payments_df['loan_status'].isin(['Late (16-30 days)','Late (31-120 days)','Charged Off'])]) # filters customers who have already defaulted on loans as well as those with late payment status \n",
    "monthly_revenue_late_customers = lost_revenue_df['instalment'].sum()\n",
    "total_monthly_revenue = loan_payments_df['instalment'].sum()\n",
    "total_revenue_pc = (monthly_revenue_late_customers/total_monthly_revenue)*100\n",
    "print(f\"total percentage of total expected revenue from late and stopped payments  = {total_revenue_pc.round(2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualise the data to examine possible indicators of loss\n",
    "- The data is visualised to see if there are possible indicators that suggest that a customer will be unable to pay their loan, leading to losses for the company\n",
    "- Subsets of the data are created, a subset containing those late on loan payments, and another subset containing those with charged off loans who are no longer paying. This enables comparison between categories of users. \n",
    "- Instances of the Plotter class and DataFrameInfo class are initialised for the main dataframe and each subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to visualise the possible indicators that a customer will not be able to pay the loan.\n",
    "loan_payments_df_stopped_paying = loan_payments_df.loc[loan_payments_df['loan_status']=='Charged Off'] # subset containing only customers who have stopped paying\n",
    "loan_payments_df_late_payments = loan_payments_df.apply(lambda row: row[loan_payments_df['loan_status'].isin(['Late (16-30 days)','Late (31-120 days)'])]) # subset containings customers with late payments\n",
    "\n",
    "# initialise instances of plotter class for each df\n",
    "original_df_plotter = Plotter(loan_payments_df)\n",
    "stopped_paying_df_plotter = Plotter(loan_payments_df_stopped_paying)\n",
    "late_payments_df_plotter = Plotter(loan_payments_df_late_payments)\n",
    "\n",
    "# intiailise instances of dataframeinfo class for each df\n",
    "original_df_info = DataFrameInfo(loan_payments_df)\n",
    "stopped_paying_df_info = DataFrameInfo(loan_payments_df_stopped_paying)\n",
    "late_payments_df_info = DataFrameInfo(loan_payments_df_late_payments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Grade of the loan\n",
    "- Countplots are generated to visualise if the loan grade is an indicator of loss\n",
    "- No signficant change is seen in the distribution for each data set, indicating this is not an indicator of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade of the loan as an indicator - NOT STRONG INDICATOR\n",
    "fig3 = plt.figure(3)\n",
    "original_df_plotter.plot_countplot('grade') # visualise distribution for all data\n",
    "fig4 = plt.figure(4)\n",
    "stopped_paying_df_plotter.plot_countplot('grade')  # visualise distribution for customers who are not paying\n",
    "fig5 = plt.figure(5)\n",
    "late_payments_df_plotter.plot_countplot('grade') # visualise distribution for customers who are late paying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Purpose of the loan\n",
    "- Countplots are generated to visualise if the loan purpose is an indicator of loss\n",
    "- No signficant change is seen in the distribution for each data set, indicating this is not an indicator of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purpose of loan as indicator - NOT STRONG INDICATOR\n",
    "fig6 = plt.figure(6)\n",
    "original_df_plotter.plot_countplot('purpose') # visualise distribution for all data\n",
    "fig7 = plt.figure(7)\n",
    "stopped_paying_df_plotter.plot_countplot('purpose')  # visualise distribution for customers who are not paying\n",
    "fig8 = plt.figure(8)\n",
    "late_payments_df_plotter.plot_countplot('purpose') # visualise distribution for customers who are late paying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Home ownership\n",
    "- Countplots are generated to visualise if home ownership status is an indicator of loss\n",
    "- No signficant change is seen in the distribution for each data set, indicating this is not an indicator of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home owenership as indicator - NOT STRONG INDICATOR\n",
    "fig9 = plt.figure(9)\n",
    "original_df_plotter.plot_countplot('home_ownership') # visualise distribution for all data\n",
    "fig10 = plt.figure(10)\n",
    "stopped_paying_df_plotter.plot_countplot('home_ownership')  # visualise distribution for customers who are not paying\n",
    "fig11 = plt.figure(11)\n",
    "late_payments_df_plotter.plot_countplot('home_ownership') # visualise distribution for customers who are late paying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Remaining amount of the loan (out_prncp)\n",
    "- KDE plots are generated to visualise if the outstanding loan amount is an indicator of loss\n",
    "- The mean remaining principal is calculated for each set of users\n",
    "- Those with late payments have a higher average remaining principal, suggesting that out_prncp is a possible loss indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_prncp as indicator - POSSIBLE INDICATOR\n",
    "fig12 = plt.figure(12)\n",
    "original_df_plotter.plot_KDE('out_prncp') # visualise distribution for all data\n",
    "fig13 = plt.figure(13)\n",
    "stopped_paying_df_plotter.plot_KDE('out_prncp')  # visualise distribution for customers who are not paying\n",
    "fig14 = plt.figure(14)\n",
    "late_payments_df_plotter.plot_KDE('out_prncp') # visualise distribution for customers who are late paying\n",
    "\n",
    "original_mean_out_prncp = original_df_info.get_mean('out_prncp') # caluclate mean for all data\n",
    "stopped_paying_mean_out_prncp = stopped_paying_df_info.get_mean('out_prncp') # calcualte mean for customers who are not paying\n",
    "late_payment_mean_out_prncp = late_payments_df_info.get_mean('out_prncp') # calcualte mean for customers who are late paying\n",
    "print(original_mean_out_prncp, stopped_paying_mean_out_prncp, late_payment_mean_out_prncp) \n",
    "# higher average out_prncp for those with late payments, suggests this is an indicator for late payments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Late fees recieved (total_rec_late_fee)\n",
    "- KDE plots are generated to visualise if the total late fees are an indicator of loss\n",
    "- The mean late fee is calculated for each set of users\n",
    "- Those with late payments or charged off loans have a higher average total late fees, suggests that total_rec_late_fee is a possible loss indicator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rec_late_fee as indicator - POSSIBLE INDICATOR\n",
    "fig15 = plt.figure(15)\n",
    "original_df_plotter.plot_KDE('total_rec_late_fee') # visualise distribution for all data\n",
    "fig16 = plt.figure(16)\n",
    "stopped_paying_df_plotter.plot_KDE('total_rec_late_fee')  # visualise distribution for customers who are not paying\n",
    "fig17 = plt.figure(17)\n",
    "late_payments_df_plotter.plot_KDE('total_rec_late_fee') # visualise distribution for customers who are late paying\n",
    "original_mean_total_rec_late_fee = original_df_info.get_mean('total_rec_late_fee') # caluclate mean for all data\n",
    "stopped_paying_mean_total_rec_late_fee = stopped_paying_df_info.get_mean('total_rec_late_fee') # calcualte mean for customers who are not paying\n",
    "late_payment_mean_total_rec_late_fee = late_payments_df_info.get_mean('total_rec_late_fee') # calcualte mean for customers who are late paying\n",
    "print(original_mean_total_rec_late_fee, stopped_paying_mean_total_rec_late_fee, late_payment_mean_total_rec_late_fee) \n",
    "# higher average total late fees for those with late payments or charged off payments, suggests this is an indicator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Interest paid (total_rec_int)\n",
    "- KDE plots are generated to visualise if the total interest paid is an indicator of loss\n",
    "- The mean interest paid is calculated for each set of users\n",
    "- Those with late payments have a higher average total interest paid, suggests that total_rec_int is a possible loss indicator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rec_int as indicator - POSSIBLE INDICATOR\n",
    "fig18 = plt.figure(18) \n",
    "original_df_plotter.plot_KDE('total_rec_int') # visualise distribution for all data\n",
    "fig18 = plt.figure(18)\n",
    "stopped_paying_df_plotter.plot_KDE('total_rec_int') # visualise distribution for customers who are not paying\n",
    "fig18 = plt.figure(18)\n",
    "late_payments_df_plotter.plot_KDE('total_rec_int') # visualise distribution for customers who are late paying\n",
    "original_mean_total_rec_int = original_df_info.get_mean('total_rec_int') # caluclate mean for all data\n",
    "stopped_paying_mean_total_rec_int = stopped_paying_df_info.get_mean('total_rec_int') # calcualte mean for customers who are not paying\n",
    "late_payment_mean_total_rec_int= late_payments_df_info.get_mean('total_rec_int') # calcualte mean for customers who are late paying\n",
    "print(original_mean_total_rec_int, stopped_paying_mean_total_rec_int, late_payment_mean_total_rec_int) \n",
    "# higher averages for late payments suggests total_rec_int is an indicator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.6 Last payment amount\n",
    "- KDE plots are generated to visualise if the last payment amount is an indicator of loss\n",
    "- The mean last payment amount is calculated for each set of users\n",
    "- Those with late payments or charged off loans have a lower average last payment amount, which suggests that last payment amount is a possible loss indicator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_payment_amount as indicator - POSSIBLE INDICATOR\n",
    "fig19 = plt.figure(19)\n",
    "original_df_plotter.plot_KDE('last_payment_amount') # visualise distribution for all data\n",
    "fig20 = plt.figure(20)\n",
    "stopped_paying_df_plotter.plot_KDE('last_payment_amount') # visualise distribution for customers who are not paying\n",
    "fig21 = plt.figure(21)\n",
    "late_payments_df_plotter.plot_KDE('last_payment_amount') # visualise distribution for customers who are late paying\n",
    "original_mean_last_payment_amount = original_df_info.get_mean('last_payment_amount') # caluclate mean for all data\n",
    "stopped_paying_mean_last_payment_amount = stopped_paying_df_info.get_mean('last_payment_amount') # calcualte mean for customers who are not paying\n",
    "late_payment_mean_last_payment_amount= late_payments_df_info.get_mean('last_payment_amount') # calcualte mean for customers who are late paying\n",
    "print(original_mean_last_payment_amount, stopped_paying_mean_last_payment_amount, late_payment_mean_last_payment_amount)\n",
    "# Last payments amount is lower for late payments and charged off payments, suggests lower last payment amount is an indicator of not paying back/paying late\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.7 Possible loss indicators summary\n",
    "- The following columns can potentially be used to indicate possible losses\n",
    "- Remaining amount of the loan (out_prncp): those with late payments have a higher average remaining principal\n",
    "- Late fees recieved (total_rec_late_fee): those with late payments or charged off loans have a higher average total late fees\n",
    "- Interest paid (total_rec_int): those with late payments have a higher average total interest paid\n",
    "- Last payment amount (lsat_payment_amount): those with late payments or charged off loans have a lower average last payment amount,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
